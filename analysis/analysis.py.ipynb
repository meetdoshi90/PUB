{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0d94cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 5\n",
    "shot = 'few'\n",
    "k = 0\n",
    "if shot=='few':\n",
    "    k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8fdeebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f'/raid/nlp/pranavg/iclr/Results_backup/generated_texts/task_{task}/llama-2-70b/'\n",
    "EVAL_PATH = f'/raid/nlp/pranavg/iclr/pragmatics/human_answers/task_{task}_human_dataset.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e33bcfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "data = pd.read_csv(f'{PATH}{shot}_shot_k{k}_run0_mcqa.csv')\n",
    "data['pretext'] = [i.strip() for i in data['pretext']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08123578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>correct answer</th>\n",
       "      <th>options</th>\n",
       "      <th>pretext</th>\n",
       "      <th>qid</th>\n",
       "      <th>wrapped_zshot</th>\n",
       "      <th>wrapped</th>\n",
       "      <th>correct_options</th>\n",
       "      <th>generate_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>Speaker_1: The chair was uncomfortable.\\nSpeak...</td>\n",
       "      <td>X1607</td>\n",
       "      <td>Speaker_1: The chair was uncomfortable.\\nSpeak...</td>\n",
       "      <td>Your task is to decide if Speaker_2 Agrees or ...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Agrees</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>Speaker_1: The idea was very creative\\nSpeaker...</td>\n",
       "      <td>X3149</td>\n",
       "      <td>Speaker_1: The idea was very creative\\nSpeaker...</td>\n",
       "      <td>Your task is to decide if Speaker_2 Agrees or ...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>Speaker_1: The girl had cheap and tacky taste....</td>\n",
       "      <td>1367</td>\n",
       "      <td>Speaker_1: The girl had cheap and tacky taste....</td>\n",
       "      <td>Your task is to decide if Speaker_2 Agrees or ...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Agrees</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>Speaker_1: The student is unwise\\nSpeaker_2: O...</td>\n",
       "      <td>873</td>\n",
       "      <td>Speaker_1: The student is unwise\\nSpeaker_2: O...</td>\n",
       "      <td>Your task is to decide if Speaker_2 Agrees or ...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>Speaker_1: Her eyes are ugly.\\nSpeaker_2: True...</td>\n",
       "      <td>X700</td>\n",
       "      <td>Speaker_1: Her eyes are ugly.\\nSpeaker_2: True...</td>\n",
       "      <td>Your task is to decide if Speaker_2 Agrees or ...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0 correct answer                  options  \\\n",
       "0             0           0      Sarcastic  ['Agrees', 'Sarcastic']   \n",
       "1             1           1         Agrees  ['Agrees', 'Sarcastic']   \n",
       "2             2           2      Sarcastic  ['Agrees', 'Sarcastic']   \n",
       "3             3           3         Agrees  ['Agrees', 'Sarcastic']   \n",
       "4             4           4      Sarcastic  ['Agrees', 'Sarcastic']   \n",
       "\n",
       "                                             pretext    qid  \\\n",
       "0  Speaker_1: The chair was uncomfortable.\\nSpeak...  X1607   \n",
       "1  Speaker_1: The idea was very creative\\nSpeaker...  X3149   \n",
       "2  Speaker_1: The girl had cheap and tacky taste....   1367   \n",
       "3  Speaker_1: The student is unwise\\nSpeaker_2: O...    873   \n",
       "4  Speaker_1: Her eyes are ugly.\\nSpeaker_2: True...   X700   \n",
       "\n",
       "                                       wrapped_zshot  \\\n",
       "0  Speaker_1: The chair was uncomfortable.\\nSpeak...   \n",
       "1  Speaker_1: The idea was very creative\\nSpeaker...   \n",
       "2  Speaker_1: The girl had cheap and tacky taste....   \n",
       "3  Speaker_1: The student is unwise\\nSpeaker_2: O...   \n",
       "4  Speaker_1: Her eyes are ugly.\\nSpeaker_2: True...   \n",
       "\n",
       "                                             wrapped correct_options  \\\n",
       "0  Your task is to decide if Speaker_2 Agrees or ...               B   \n",
       "1  Your task is to decide if Speaker_2 Agrees or ...               A   \n",
       "2  Your task is to decide if Speaker_2 Agrees or ...               B   \n",
       "3  Your task is to decide if Speaker_2 Agrees or ...               A   \n",
       "4  Your task is to decide if Speaker_2 Agrees or ...               B   \n",
       "\n",
       "  generate_predictions  \n",
       "0                    B  \n",
       "1                    B  \n",
       "2                    B  \n",
       "3                    B  \n",
       "4                    B  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef5d8701",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = data.loc[data['correct_options'] != data['generate_predictions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a7aef4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>correct answer</th>\n",
       "      <th>options</th>\n",
       "      <th>pretext</th>\n",
       "      <th>qid</th>\n",
       "      <th>wrapped_zshot</th>\n",
       "      <th>wrapped</th>\n",
       "      <th>correct_options</th>\n",
       "      <th>generate_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Agrees</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>Speaker_1: The idea was very creative\\nSpeaker...</td>\n",
       "      <td>X3149</td>\n",
       "      <td>Speaker_1: The idea was very creative\\nSpeaker...</td>\n",
       "      <td>Your task is to decide if Speaker_2 Agrees or ...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Agrees</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>Speaker_1: The student is unwise\\nSpeaker_2: O...</td>\n",
       "      <td>873</td>\n",
       "      <td>Speaker_1: The student is unwise\\nSpeaker_2: O...</td>\n",
       "      <td>Your task is to decide if Speaker_2 Agrees or ...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>Agrees</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>Speaker_1: The pizza was good.\\nSpeaker_2: Tru...</td>\n",
       "      <td>X2476</td>\n",
       "      <td>Speaker_1: The pizza was good.\\nSpeaker_2: Tru...</td>\n",
       "      <td>Your task is to decide if Speaker_2 Agrees or ...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>Agrees</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>Speaker_1: The book is over stimulating\\nSpeak...</td>\n",
       "      <td>438</td>\n",
       "      <td>Speaker_1: The book is over stimulating\\nSpeak...</td>\n",
       "      <td>Your task is to decide if Speaker_2 Agrees or ...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Agrees</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>Speaker_1: It has plenty of use\\nSpeaker_2: Of...</td>\n",
       "      <td>X3003</td>\n",
       "      <td>Speaker_1: It has plenty of use\\nSpeaker_2: Of...</td>\n",
       "      <td>Your task is to decide if Speaker_2 Agrees or ...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0.1  Unnamed: 0 correct answer                  options  \\\n",
       "1              1           1         Agrees  ['Agrees', 'Sarcastic']   \n",
       "3              3           3         Agrees  ['Agrees', 'Sarcastic']   \n",
       "6              6           6         Agrees  ['Agrees', 'Sarcastic']   \n",
       "8              8           8         Agrees  ['Agrees', 'Sarcastic']   \n",
       "10            10          10         Agrees  ['Agrees', 'Sarcastic']   \n",
       "\n",
       "                                              pretext    qid  \\\n",
       "1   Speaker_1: The idea was very creative\\nSpeaker...  X3149   \n",
       "3   Speaker_1: The student is unwise\\nSpeaker_2: O...    873   \n",
       "6   Speaker_1: The pizza was good.\\nSpeaker_2: Tru...  X2476   \n",
       "8   Speaker_1: The book is over stimulating\\nSpeak...    438   \n",
       "10  Speaker_1: It has plenty of use\\nSpeaker_2: Of...  X3003   \n",
       "\n",
       "                                        wrapped_zshot  \\\n",
       "1   Speaker_1: The idea was very creative\\nSpeaker...   \n",
       "3   Speaker_1: The student is unwise\\nSpeaker_2: O...   \n",
       "6   Speaker_1: The pizza was good.\\nSpeaker_2: Tru...   \n",
       "8   Speaker_1: The book is over stimulating\\nSpeak...   \n",
       "10  Speaker_1: It has plenty of use\\nSpeaker_2: Of...   \n",
       "\n",
       "                                              wrapped correct_options  \\\n",
       "1   Your task is to decide if Speaker_2 Agrees or ...               A   \n",
       "3   Your task is to decide if Speaker_2 Agrees or ...               A   \n",
       "6   Your task is to decide if Speaker_2 Agrees or ...               A   \n",
       "8   Your task is to decide if Speaker_2 Agrees or ...               A   \n",
       "10  Your task is to decide if Speaker_2 Agrees or ...               A   \n",
       "\n",
       "   generate_predictions  \n",
       "1                     B  \n",
       "3                     B  \n",
       "6                     B  \n",
       "8                     B  \n",
       "10                    B  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b65e9b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Speaker_1: The idea was very creative\\nSpeaker_2: True, the man's idea had the creativity of a young child\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered.iloc[0]['pretext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "669c0d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "814"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e2491d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_json(EVAL_PATH, orient='records')\n",
    "df2['text'] = [i['text'] for i in df2['data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6be0762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"\"\n",
    "if task==0:\n",
    "    path = \"/raid/nlp/pranavg/iclr/Human_eval/project-2-at-2023-09-28-14-30-fa04304f.json\"\n",
    "elif task==1:\n",
    "    path = '/raid/nlp/pranavg/iclr/Human_eval/project-3-at-2023-09-28-14-47-2716a422.json'\n",
    "elif task==2:\n",
    "    path = \"/raid/nlp/pranavg/iclr/Human_eval/project-9-at-2023-09-28-14-51-bfc251c0.json\"\n",
    "elif task==3:\n",
    "    path = \"/raid/nlp/pranavg/iclr/Human_eval/project-10-at-2023-09-28-14-52-70c0a31f.json\"\n",
    "elif task == 4:\n",
    "    path = \"/raid/nlp/pranavg/iclr/Human_eval/project-4-at-2023-09-28-14-55-d9d9a9f8.json\"\n",
    "elif task == 5:\n",
    "    path = \"/raid/nlp/pranavg/iclr/Human_eval/project-5-at-2023-09-28-15-03-1abedb7a.json\"\n",
    "elif task == 6:\n",
    "    path = \"/raid/nlp/pranavg/iclr/Human_eval/project-6-at-2023-09-28-15-09-9779d801.json\"\n",
    "elif task == 7:\n",
    "    path = \"/raid/nlp/pranavg/iclr/Human_eval/project-7-at-2023-09-28-15-21-1d2ae190.json\"\n",
    "elif task == 8:\n",
    "    path = \"/raid/nlp/pranavg/iclr/Human_eval/project-20-at-2023-09-28-18-08-400941e2.json\"\n",
    "elif task == 9:\n",
    "    path = \"/raid/nlp/pranavg/iclr/Human_eval/project-11-at-2023-09-28-15-31-6690410d.json\"\n",
    "elif task == 10:\n",
    "    path = \"/raid/nlp/pranavg/iclr/Human_eval/project-12-at-2023-09-28-15-49-0f8c1648.json\"\n",
    "elif task == 11:\n",
    "    path = \"/raid/nlp/pranavg/iclr/Human_eval/project-13-at-2023-09-29-03-49-e928eda7.json\"\n",
    "elif task == 12:\n",
    "    path = \"\"\n",
    "elif task == 13:\n",
    "    path = \"/raid/nlp/pranavg/iclr/Human_eval/project-14-at-2023-09-28-15-34-b61b2b89.json\"\n",
    "elif task == 14:\n",
    "    path = \"/raid/nlp/pranavg/iclr/Human_eval/project-15-at-2023-09-28-15-36-97e9e16d.json\"\n",
    "    \n",
    "df1 = pd.read_json(path, orient='records')\n",
    "corr1 = []\n",
    "corr2 = []\n",
    "corr3 = []\n",
    "for i in range(len(df1)):\n",
    "    try:\n",
    "        corr1.append(df1['annotations'][i][0]['result'][0]['value']['choices'][0])\n",
    "    except:\n",
    "        corr1.append(\"\")\n",
    "    try:\n",
    "        corr2.append(df1['annotations'][i][1]['result'][0]['value']['choices'][0])\n",
    "    except:\n",
    "        corr2.append('')\n",
    "    try:\n",
    "        corr3.append(df1['annotations'][i][2]['result'][0]['value']['choices'][0])\n",
    "    except:\n",
    "        corr3.append('')\n",
    "df1['ann1'] = corr1\n",
    "df1['ann2'] = corr2\n",
    "df1['ann3'] = corr3\n",
    "df1['text'] = [i['text'] for i in df1['data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f9498c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which of the following options is correct about the conversation given below:\\nSpeaker_1: Life is full of wonder and color where the experience is beneficial to all\\nSpeaker_2: Yeah, Life is simply a board game of Risk'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.iloc[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24683cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annotations</th>\n",
       "      <th>file_upload</th>\n",
       "      <th>drafts</th>\n",
       "      <th>predictions</th>\n",
       "      <th>data</th>\n",
       "      <th>meta</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>inner_id</th>\n",
       "      <th>...</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>unresolved_comment_count</th>\n",
       "      <th>last_comment_updated_at</th>\n",
       "      <th>project</th>\n",
       "      <th>updated_by</th>\n",
       "      <th>comment_authors</th>\n",
       "      <th>ann1</th>\n",
       "      <th>ann2</th>\n",
       "      <th>ann3</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4426</td>\n",
       "      <td>[{'id': 1535, 'completed_by': 11, 'result': [{...</td>\n",
       "      <td>0652cd01-task_5_human_dataset.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2023-09-14 06:47:54.893359+00:00</td>\n",
       "      <td>2023-09-24 05:26:21.402781+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "      <td>Which of the following options is correct abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4427</td>\n",
       "      <td>[{'id': 1536, 'completed_by': 11, 'result': [{...</td>\n",
       "      <td>0652cd01-task_5_human_dataset.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2023-09-14 06:47:54.893475+00:00</td>\n",
       "      <td>2023-09-24 05:26:32.034569+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "      <td>Which of the following options is correct abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4428</td>\n",
       "      <td>[{'id': 1537, 'completed_by': 11, 'result': [{...</td>\n",
       "      <td>0652cd01-task_5_human_dataset.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2023-09-14 06:47:54.893556+00:00</td>\n",
       "      <td>2023-09-24 05:26:39.017210+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "      <td>Which of the following options is correct abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4429</td>\n",
       "      <td>[{'id': 1538, 'completed_by': 11, 'result': [{...</td>\n",
       "      <td>0652cd01-task_5_human_dataset.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2023-09-14 06:47:54.893634+00:00</td>\n",
       "      <td>2023-09-24 05:26:45.863090+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "      <td>Which of the following options is correct abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4430</td>\n",
       "      <td>[{'id': 1539, 'completed_by': 11, 'result': [{...</td>\n",
       "      <td>0652cd01-task_5_human_dataset.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2023-09-14 06:47:54.893711+00:00</td>\n",
       "      <td>2023-09-24 05:26:51.668015+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "      <td>Which of the following options is correct abou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        annotations  \\\n",
       "0  4426  [{'id': 1535, 'completed_by': 11, 'result': [{...   \n",
       "1  4427  [{'id': 1536, 'completed_by': 11, 'result': [{...   \n",
       "2  4428  [{'id': 1537, 'completed_by': 11, 'result': [{...   \n",
       "3  4429  [{'id': 1538, 'completed_by': 11, 'result': [{...   \n",
       "4  4430  [{'id': 1539, 'completed_by': 11, 'result': [{...   \n",
       "\n",
       "                          file_upload drafts predictions  \\\n",
       "0  0652cd01-task_5_human_dataset.json     []          []   \n",
       "1  0652cd01-task_5_human_dataset.json     []          []   \n",
       "2  0652cd01-task_5_human_dataset.json     []          []   \n",
       "3  0652cd01-task_5_human_dataset.json     []          []   \n",
       "4  0652cd01-task_5_human_dataset.json     []          []   \n",
       "\n",
       "                                                data meta  \\\n",
       "0  {'text': 'Which of the following options is co...   {}   \n",
       "1  {'text': 'Which of the following options is co...   {}   \n",
       "2  {'text': 'Which of the following options is co...   {}   \n",
       "3  {'text': 'Which of the following options is co...   {}   \n",
       "4  {'text': 'Which of the following options is co...   {}   \n",
       "\n",
       "                        created_at                       updated_at  inner_id  \\\n",
       "0 2023-09-14 06:47:54.893359+00:00 2023-09-24 05:26:21.402781+00:00         1   \n",
       "1 2023-09-14 06:47:54.893475+00:00 2023-09-24 05:26:32.034569+00:00         2   \n",
       "2 2023-09-14 06:47:54.893556+00:00 2023-09-24 05:26:39.017210+00:00         3   \n",
       "3 2023-09-14 06:47:54.893634+00:00 2023-09-24 05:26:45.863090+00:00         4   \n",
       "4 2023-09-14 06:47:54.893711+00:00 2023-09-24 05:26:51.668015+00:00         5   \n",
       "\n",
       "   ...  comment_count  unresolved_comment_count  last_comment_updated_at  \\\n",
       "0  ...              0                         0                      NaT   \n",
       "1  ...              0                         0                      NaT   \n",
       "2  ...              0                         0                      NaT   \n",
       "3  ...              0                         0                      NaT   \n",
       "4  ...              0                         0                      NaT   \n",
       "\n",
       "   project  updated_by comment_authors  \\\n",
       "0        5          17              []   \n",
       "1        5          17              []   \n",
       "2        5          17              []   \n",
       "3        5          17              []   \n",
       "4        5          17              []   \n",
       "\n",
       "                                          ann1  \\\n",
       "0  Speaker_2 is being sarcastic with Speaker_1   \n",
       "1  Speaker_2 is being sarcastic with Speaker_1   \n",
       "2  Speaker_2 is being sarcastic with Speaker_1   \n",
       "3  Speaker_2 is being sarcastic with Speaker_1   \n",
       "4  Speaker_2 is being sarcastic with Speaker_1   \n",
       "\n",
       "                                          ann2 ann3  \\\n",
       "0  Speaker_2 is being sarcastic with Speaker_1        \n",
       "1  Speaker_2 is being sarcastic with Speaker_1        \n",
       "2  Speaker_2 is being sarcastic with Speaker_1        \n",
       "3  Speaker_2 is being sarcastic with Speaker_1        \n",
       "4  Speaker_2 is being sarcastic with Speaker_1        \n",
       "\n",
       "                                                text  \n",
       "0  Which of the following options is correct abou...  \n",
       "1  Which of the following options is correct abou...  \n",
       "2  Which of the following options is correct abou...  \n",
       "3  Which of the following options is correct abou...  \n",
       "4  Which of the following options is correct abou...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38a755da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which of the following options is correct about the conversation given below:\\nSpeaker_1: Life is full of wonder and color where the experience is beneficial to all\\nSpeaker_2: Yeah, Life is simply a board game of Risk'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.iloc[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "539261a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>answer</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Which of the following options is correct abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Which of the following options is correct abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Which of the following options is correct abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Which of the following options is correct abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Which of the following options is correct abou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data     answer  \\\n",
       "0  {'text': 'Which of the following options is co...  Sarcastic   \n",
       "1  {'text': 'Which of the following options is co...  Sarcastic   \n",
       "2  {'text': 'Which of the following options is co...  Sarcastic   \n",
       "3  {'text': 'Which of the following options is co...  Sarcastic   \n",
       "4  {'text': 'Which of the following options is co...  Sarcastic   \n",
       "\n",
       "                                                text  \n",
       "0  Which of the following options is correct abou...  \n",
       "1  Which of the following options is correct abou...  \n",
       "2  Which of the following options is correct abou...  \n",
       "3  Which of the following options is correct abou...  \n",
       "4  Which of the following options is correct abou...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3f0a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df2.merge(df1, left_on='text', right_on='text', how='inner',sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c10f7e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_x</th>\n",
       "      <th>answer</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>annotations</th>\n",
       "      <th>file_upload</th>\n",
       "      <th>drafts</th>\n",
       "      <th>predictions</th>\n",
       "      <th>data_y</th>\n",
       "      <th>meta</th>\n",
       "      <th>...</th>\n",
       "      <th>total_predictions</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>unresolved_comment_count</th>\n",
       "      <th>last_comment_updated_at</th>\n",
       "      <th>project</th>\n",
       "      <th>updated_by</th>\n",
       "      <th>comment_authors</th>\n",
       "      <th>ann1</th>\n",
       "      <th>ann2</th>\n",
       "      <th>ann3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Which of the following options is correct abou...</td>\n",
       "      <td>4426</td>\n",
       "      <td>[{'id': 1535, 'completed_by': 11, 'result': [{...</td>\n",
       "      <td>0652cd01-task_5_human_dataset.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>{}</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Which of the following options is correct abou...</td>\n",
       "      <td>4427</td>\n",
       "      <td>[{'id': 1536, 'completed_by': 11, 'result': [{...</td>\n",
       "      <td>0652cd01-task_5_human_dataset.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>{}</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Which of the following options is correct abou...</td>\n",
       "      <td>4428</td>\n",
       "      <td>[{'id': 1537, 'completed_by': 11, 'result': [{...</td>\n",
       "      <td>0652cd01-task_5_human_dataset.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>{}</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Which of the following options is correct abou...</td>\n",
       "      <td>4429</td>\n",
       "      <td>[{'id': 1538, 'completed_by': 11, 'result': [{...</td>\n",
       "      <td>0652cd01-task_5_human_dataset.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>{}</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Which of the following options is correct abou...</td>\n",
       "      <td>4430</td>\n",
       "      <td>[{'id': 1539, 'completed_by': 11, 'result': [{...</td>\n",
       "      <td>0652cd01-task_5_human_dataset.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>{}</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              data_x     answer  \\\n",
       "0  {'text': 'Which of the following options is co...  Sarcastic   \n",
       "1  {'text': 'Which of the following options is co...  Sarcastic   \n",
       "2  {'text': 'Which of the following options is co...  Sarcastic   \n",
       "3  {'text': 'Which of the following options is co...  Sarcastic   \n",
       "4  {'text': 'Which of the following options is co...  Sarcastic   \n",
       "\n",
       "                                                text    id  \\\n",
       "0  Which of the following options is correct abou...  4426   \n",
       "1  Which of the following options is correct abou...  4427   \n",
       "2  Which of the following options is correct abou...  4428   \n",
       "3  Which of the following options is correct abou...  4429   \n",
       "4  Which of the following options is correct abou...  4430   \n",
       "\n",
       "                                         annotations  \\\n",
       "0  [{'id': 1535, 'completed_by': 11, 'result': [{...   \n",
       "1  [{'id': 1536, 'completed_by': 11, 'result': [{...   \n",
       "2  [{'id': 1537, 'completed_by': 11, 'result': [{...   \n",
       "3  [{'id': 1538, 'completed_by': 11, 'result': [{...   \n",
       "4  [{'id': 1539, 'completed_by': 11, 'result': [{...   \n",
       "\n",
       "                          file_upload drafts predictions  \\\n",
       "0  0652cd01-task_5_human_dataset.json     []          []   \n",
       "1  0652cd01-task_5_human_dataset.json     []          []   \n",
       "2  0652cd01-task_5_human_dataset.json     []          []   \n",
       "3  0652cd01-task_5_human_dataset.json     []          []   \n",
       "4  0652cd01-task_5_human_dataset.json     []          []   \n",
       "\n",
       "                                              data_y meta  ...  \\\n",
       "0  {'text': 'Which of the following options is co...   {}  ...   \n",
       "1  {'text': 'Which of the following options is co...   {}  ...   \n",
       "2  {'text': 'Which of the following options is co...   {}  ...   \n",
       "3  {'text': 'Which of the following options is co...   {}  ...   \n",
       "4  {'text': 'Which of the following options is co...   {}  ...   \n",
       "\n",
       "  total_predictions comment_count  unresolved_comment_count  \\\n",
       "0                 0             0                         0   \n",
       "1                 0             0                         0   \n",
       "2                 0             0                         0   \n",
       "3                 0             0                         0   \n",
       "4                 0             0                         0   \n",
       "\n",
       "   last_comment_updated_at  project  updated_by  comment_authors  \\\n",
       "0                      NaT        5          17               []   \n",
       "1                      NaT        5          17               []   \n",
       "2                      NaT        5          17               []   \n",
       "3                      NaT        5          17               []   \n",
       "4                      NaT        5          17               []   \n",
       "\n",
       "                                          ann1  \\\n",
       "0  Speaker_2 is being sarcastic with Speaker_1   \n",
       "1  Speaker_2 is being sarcastic with Speaker_1   \n",
       "2  Speaker_2 is being sarcastic with Speaker_1   \n",
       "3  Speaker_2 is being sarcastic with Speaker_1   \n",
       "4  Speaker_2 is being sarcastic with Speaker_1   \n",
       "\n",
       "                                          ann2  ann3  \n",
       "0  Speaker_2 is being sarcastic with Speaker_1        \n",
       "1  Speaker_2 is being sarcastic with Speaker_1        \n",
       "2  Speaker_2 is being sarcastic with Speaker_1        \n",
       "3  Speaker_2 is being sarcastic with Speaker_1        \n",
       "4  Speaker_2 is being sarcastic with Speaker_1        \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33fd865e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_x                      {'text': 'Which of the following options is co...\n",
       "answer                                                              Sarcastic\n",
       "text                        Which of the following options is correct abou...\n",
       "id                                                                       4426\n",
       "annotations                 [{'id': 1535, 'completed_by': 11, 'result': [{...\n",
       "file_upload                                0652cd01-task_5_human_dataset.json\n",
       "drafts                                                                     []\n",
       "predictions                                                                []\n",
       "data_y                      {'text': 'Which of the following options is co...\n",
       "meta                                                                       {}\n",
       "created_at                                   2023-09-14 06:47:54.893359+00:00\n",
       "updated_at                                   2023-09-24 05:26:21.402781+00:00\n",
       "inner_id                                                                    1\n",
       "total_annotations                                                           2\n",
       "cancelled_annotations                                                       0\n",
       "total_predictions                                                           0\n",
       "comment_count                                                               0\n",
       "unresolved_comment_count                                                    0\n",
       "last_comment_updated_at                                                   NaT\n",
       "project                                                                     5\n",
       "updated_by                                                                 17\n",
       "comment_authors                                                            []\n",
       "ann1                              Speaker_2 is being sarcastic with Speaker_1\n",
       "ann2                              Speaker_2 is being sarcastic with Speaker_1\n",
       "ann3                                                                         \n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91e255da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_x</th>\n",
       "      <th>answer</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>annotations</th>\n",
       "      <th>file_upload</th>\n",
       "      <th>drafts</th>\n",
       "      <th>predictions</th>\n",
       "      <th>data_y</th>\n",
       "      <th>meta</th>\n",
       "      <th>...</th>\n",
       "      <th>total_predictions</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>unresolved_comment_count</th>\n",
       "      <th>last_comment_updated_at</th>\n",
       "      <th>project</th>\n",
       "      <th>updated_by</th>\n",
       "      <th>comment_authors</th>\n",
       "      <th>ann1</th>\n",
       "      <th>ann2</th>\n",
       "      <th>ann3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Which of the following options is correct abou...</td>\n",
       "      <td>4426</td>\n",
       "      <td>[{'id': 1535, 'completed_by': 11, 'result': [{...</td>\n",
       "      <td>0652cd01-task_5_human_dataset.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>{}</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Which of the following options is correct abou...</td>\n",
       "      <td>4427</td>\n",
       "      <td>[{'id': 1536, 'completed_by': 11, 'result': [{...</td>\n",
       "      <td>0652cd01-task_5_human_dataset.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>{}</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Which of the following options is correct abou...</td>\n",
       "      <td>4428</td>\n",
       "      <td>[{'id': 1537, 'completed_by': 11, 'result': [{...</td>\n",
       "      <td>0652cd01-task_5_human_dataset.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>{}</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Which of the following options is correct abou...</td>\n",
       "      <td>4429</td>\n",
       "      <td>[{'id': 1538, 'completed_by': 11, 'result': [{...</td>\n",
       "      <td>0652cd01-task_5_human_dataset.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>{}</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Which of the following options is correct abou...</td>\n",
       "      <td>4430</td>\n",
       "      <td>[{'id': 1539, 'completed_by': 11, 'result': [{...</td>\n",
       "      <td>0652cd01-task_5_human_dataset.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'text': 'Which of the following options is co...</td>\n",
       "      <td>{}</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              data_x     answer  \\\n",
       "0  {'text': 'Which of the following options is co...  Sarcastic   \n",
       "1  {'text': 'Which of the following options is co...  Sarcastic   \n",
       "2  {'text': 'Which of the following options is co...  Sarcastic   \n",
       "3  {'text': 'Which of the following options is co...  Sarcastic   \n",
       "4  {'text': 'Which of the following options is co...  Sarcastic   \n",
       "\n",
       "                                                text    id  \\\n",
       "0  Which of the following options is correct abou...  4426   \n",
       "1  Which of the following options is correct abou...  4427   \n",
       "2  Which of the following options is correct abou...  4428   \n",
       "3  Which of the following options is correct abou...  4429   \n",
       "4  Which of the following options is correct abou...  4430   \n",
       "\n",
       "                                         annotations  \\\n",
       "0  [{'id': 1535, 'completed_by': 11, 'result': [{...   \n",
       "1  [{'id': 1536, 'completed_by': 11, 'result': [{...   \n",
       "2  [{'id': 1537, 'completed_by': 11, 'result': [{...   \n",
       "3  [{'id': 1538, 'completed_by': 11, 'result': [{...   \n",
       "4  [{'id': 1539, 'completed_by': 11, 'result': [{...   \n",
       "\n",
       "                          file_upload drafts predictions  \\\n",
       "0  0652cd01-task_5_human_dataset.json     []          []   \n",
       "1  0652cd01-task_5_human_dataset.json     []          []   \n",
       "2  0652cd01-task_5_human_dataset.json     []          []   \n",
       "3  0652cd01-task_5_human_dataset.json     []          []   \n",
       "4  0652cd01-task_5_human_dataset.json     []          []   \n",
       "\n",
       "                                              data_y meta  ...  \\\n",
       "0  {'text': 'Which of the following options is co...   {}  ...   \n",
       "1  {'text': 'Which of the following options is co...   {}  ...   \n",
       "2  {'text': 'Which of the following options is co...   {}  ...   \n",
       "3  {'text': 'Which of the following options is co...   {}  ...   \n",
       "4  {'text': 'Which of the following options is co...   {}  ...   \n",
       "\n",
       "  total_predictions comment_count  unresolved_comment_count  \\\n",
       "0                 0             0                         0   \n",
       "1                 0             0                         0   \n",
       "2                 0             0                         0   \n",
       "3                 0             0                         0   \n",
       "4                 0             0                         0   \n",
       "\n",
       "   last_comment_updated_at  project  updated_by  comment_authors  \\\n",
       "0                      NaT        5          17               []   \n",
       "1                      NaT        5          17               []   \n",
       "2                      NaT        5          17               []   \n",
       "3                      NaT        5          17               []   \n",
       "4                      NaT        5          17               []   \n",
       "\n",
       "                                          ann1  \\\n",
       "0  Speaker_2 is being sarcastic with Speaker_1   \n",
       "1  Speaker_2 is being sarcastic with Speaker_1   \n",
       "2  Speaker_2 is being sarcastic with Speaker_1   \n",
       "3  Speaker_2 is being sarcastic with Speaker_1   \n",
       "4  Speaker_2 is being sarcastic with Speaker_1   \n",
       "\n",
       "                                          ann2  ann3  \n",
       "0  Speaker_2 is being sarcastic with Speaker_1        \n",
       "1  Speaker_2 is being sarcastic with Speaker_1        \n",
       "2  Speaker_2 is being sarcastic with Speaker_1        \n",
       "3  Speaker_2 is being sarcastic with Speaker_1        \n",
       "4  Speaker_2 is being sarcastic with Speaker_1        \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d43ece9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Speaker_1: The idea was very creative\\nSpeaker_2: True, the man's idea had the creativity of a young child\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_filtered.iloc[0]['pretext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64a3e6a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Which of the following options is correct about the conversation given below:\\nSpeaker_1: Life is full of wonder and color where the experience is beneficial to all\\nSpeaker_2: Yeah, Life is simply a board game of Risk'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.iloc[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efd2249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re.sub('^.*?\\nContext','Context',i.strip().replace('\\nAnswer','\\nY').replace('\\nQuestion','\\nX')) \n",
    "merged_df['cropped_answer'] = [re.sub(\"Which of the following options is correct about the conversation given below:\\nSpeaker_1\",'Speaker_1',i.strip().replace('\\nAnswer','\\nResponse')) for i in merged_df['text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5110751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Speaker_1: Life is full of wonder and color where the experience is beneficial to all\\nSpeaker_2: Yeah, Life is simply a board game of Risk'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.iloc[0]['cropped_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c80c88ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fff58a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "814"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a3dc11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_model_df = data.merge(merged_df, left_on='pretext', right_on='cropped_answer', how='inner',sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c34e5c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>correct answer</th>\n",
       "      <th>options</th>\n",
       "      <th>pretext</th>\n",
       "      <th>qid</th>\n",
       "      <th>wrapped_zshot</th>\n",
       "      <th>wrapped</th>\n",
       "      <th>correct_options</th>\n",
       "      <th>generate_predictions</th>\n",
       "      <th>...</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>unresolved_comment_count</th>\n",
       "      <th>last_comment_updated_at</th>\n",
       "      <th>project</th>\n",
       "      <th>updated_by</th>\n",
       "      <th>comment_authors</th>\n",
       "      <th>ann1</th>\n",
       "      <th>ann2</th>\n",
       "      <th>ann3</th>\n",
       "      <th>cropped_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>Agrees</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>Speaker_1: Her butt was flat and uninteresting...</td>\n",
       "      <td>455</td>\n",
       "      <td>Speaker_1: Her butt was flat and uninteresting...</td>\n",
       "      <td>Your task is to decide if Speaker_2 Agrees or ...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Speaker_2 agrees with Speaker_1</td>\n",
       "      <td>Speaker_2 agrees with Speaker_1</td>\n",
       "      <td></td>\n",
       "      <td>Speaker_1: Her butt was flat and uninteresting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>Speaker_1: The movie is new\\nSpeaker_2: Of cou...</td>\n",
       "      <td>X2040</td>\n",
       "      <td>Speaker_1: The movie is new\\nSpeaker_2: Of cou...</td>\n",
       "      <td>Your task is to decide if Speaker_2 Agrees or ...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "      <td>Speaker_1: The movie is new\\nSpeaker_2: Of cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152</td>\n",
       "      <td>152</td>\n",
       "      <td>Agrees</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>Speaker_1: His anger is intense\\nSpeaker_2: Ye...</td>\n",
       "      <td>X107</td>\n",
       "      <td>Speaker_1: His anger is intense\\nSpeaker_2: Ye...</td>\n",
       "      <td>Your task is to decide if Speaker_2 Agrees or ...</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Speaker_2 agrees with Speaker_1</td>\n",
       "      <td>Speaker_2 agrees with Speaker_1</td>\n",
       "      <td></td>\n",
       "      <td>Speaker_1: His anger is intense\\nSpeaker_2: Ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153</td>\n",
       "      <td>153</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>Speaker_1: His political opinions were very co...</td>\n",
       "      <td>X2919</td>\n",
       "      <td>Speaker_1: His political opinions were very co...</td>\n",
       "      <td>Your task is to decide if Speaker_2 Agrees or ...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "      <td>Speaker_1: His political opinions were very co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>Speaker_1: The song is emotional and profound....</td>\n",
       "      <td>X1864</td>\n",
       "      <td>Speaker_1: The song is emotional and profound....</td>\n",
       "      <td>Your task is to decide if Speaker_2 Agrees or ...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "      <td>Speaker_1: The song is emotional and profound....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0 correct answer                  options  \\\n",
       "0           117         117         Agrees  ['Agrees', 'Sarcastic']   \n",
       "1           120         120      Sarcastic  ['Agrees', 'Sarcastic']   \n",
       "2           152         152         Agrees  ['Agrees', 'Sarcastic']   \n",
       "3           153         153      Sarcastic  ['Agrees', 'Sarcastic']   \n",
       "4           188         188      Sarcastic  ['Agrees', 'Sarcastic']   \n",
       "\n",
       "                                             pretext    qid  \\\n",
       "0  Speaker_1: Her butt was flat and uninteresting...    455   \n",
       "1  Speaker_1: The movie is new\\nSpeaker_2: Of cou...  X2040   \n",
       "2  Speaker_1: His anger is intense\\nSpeaker_2: Ye...   X107   \n",
       "3  Speaker_1: His political opinions were very co...  X2919   \n",
       "4  Speaker_1: The song is emotional and profound....  X1864   \n",
       "\n",
       "                                       wrapped_zshot  \\\n",
       "0  Speaker_1: Her butt was flat and uninteresting...   \n",
       "1  Speaker_1: The movie is new\\nSpeaker_2: Of cou...   \n",
       "2  Speaker_1: His anger is intense\\nSpeaker_2: Ye...   \n",
       "3  Speaker_1: His political opinions were very co...   \n",
       "4  Speaker_1: The song is emotional and profound....   \n",
       "\n",
       "                                             wrapped correct_options  \\\n",
       "0  Your task is to decide if Speaker_2 Agrees or ...               A   \n",
       "1  Your task is to decide if Speaker_2 Agrees or ...               B   \n",
       "2  Your task is to decide if Speaker_2 Agrees or ...               A   \n",
       "3  Your task is to decide if Speaker_2 Agrees or ...               B   \n",
       "4  Your task is to decide if Speaker_2 Agrees or ...               B   \n",
       "\n",
       "  generate_predictions  ... comment_count unresolved_comment_count  \\\n",
       "0                    B  ...             0                        0   \n",
       "1                    B  ...             0                        0   \n",
       "2                    B  ...             0                        0   \n",
       "3                    B  ...             0                        0   \n",
       "4                    B  ...             0                        0   \n",
       "\n",
       "  last_comment_updated_at  project updated_by comment_authors  \\\n",
       "0                     NaT        5         17              []   \n",
       "1                     NaT        5         17              []   \n",
       "2                     NaT        5         17              []   \n",
       "3                     NaT        5         17              []   \n",
       "4                     NaT        5         17              []   \n",
       "\n",
       "                                          ann1  \\\n",
       "0              Speaker_2 agrees with Speaker_1   \n",
       "1  Speaker_2 is being sarcastic with Speaker_1   \n",
       "2              Speaker_2 agrees with Speaker_1   \n",
       "3  Speaker_2 is being sarcastic with Speaker_1   \n",
       "4  Speaker_2 is being sarcastic with Speaker_1   \n",
       "\n",
       "                                          ann2 ann3  \\\n",
       "0              Speaker_2 agrees with Speaker_1        \n",
       "1  Speaker_2 is being sarcastic with Speaker_1        \n",
       "2              Speaker_2 agrees with Speaker_1        \n",
       "3  Speaker_2 is being sarcastic with Speaker_1        \n",
       "4  Speaker_2 is being sarcastic with Speaker_1        \n",
       "\n",
       "                                      cropped_answer  \n",
       "0  Speaker_1: Her butt was flat and uninteresting...  \n",
       "1  Speaker_1: The movie is new\\nSpeaker_2: Of cou...  \n",
       "2  Speaker_1: His anger is intense\\nSpeaker_2: Ye...  \n",
       "3  Speaker_1: His political opinions were very co...  \n",
       "4  Speaker_1: The song is emotional and profound....  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bdb2d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_model_df = human_model_df[['correct answer', 'pretext','options','correct_options','generate_predictions','ann1','ann2','ann3','cropped_answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8352e906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct answer</th>\n",
       "      <th>pretext</th>\n",
       "      <th>options</th>\n",
       "      <th>correct_options</th>\n",
       "      <th>generate_predictions</th>\n",
       "      <th>ann1</th>\n",
       "      <th>ann2</th>\n",
       "      <th>ann3</th>\n",
       "      <th>cropped_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agrees</td>\n",
       "      <td>Speaker_1: Her butt was flat and uninteresting...</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>Speaker_2 agrees with Speaker_1</td>\n",
       "      <td>Speaker_2 agrees with Speaker_1</td>\n",
       "      <td></td>\n",
       "      <td>Speaker_1: Her butt was flat and uninteresting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Speaker_1: The movie is new\\nSpeaker_2: Of cou...</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "      <td>Speaker_1: The movie is new\\nSpeaker_2: Of cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agrees</td>\n",
       "      <td>Speaker_1: His anger is intense\\nSpeaker_2: Ye...</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>Speaker_2 agrees with Speaker_1</td>\n",
       "      <td>Speaker_2 agrees with Speaker_1</td>\n",
       "      <td></td>\n",
       "      <td>Speaker_1: His anger is intense\\nSpeaker_2: Ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Speaker_1: His political opinions were very co...</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "      <td>Speaker_1: His political opinions were very co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Speaker_1: The song is emotional and profound....</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "      <td>Speaker_1: The song is emotional and profound....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  correct answer                                            pretext  \\\n",
       "0         Agrees  Speaker_1: Her butt was flat and uninteresting...   \n",
       "1      Sarcastic  Speaker_1: The movie is new\\nSpeaker_2: Of cou...   \n",
       "2         Agrees  Speaker_1: His anger is intense\\nSpeaker_2: Ye...   \n",
       "3      Sarcastic  Speaker_1: His political opinions were very co...   \n",
       "4      Sarcastic  Speaker_1: The song is emotional and profound....   \n",
       "\n",
       "                   options correct_options generate_predictions  \\\n",
       "0  ['Agrees', 'Sarcastic']               A                    B   \n",
       "1  ['Agrees', 'Sarcastic']               B                    B   \n",
       "2  ['Agrees', 'Sarcastic']               A                    B   \n",
       "3  ['Agrees', 'Sarcastic']               B                    B   \n",
       "4  ['Agrees', 'Sarcastic']               B                    B   \n",
       "\n",
       "                                          ann1  \\\n",
       "0              Speaker_2 agrees with Speaker_1   \n",
       "1  Speaker_2 is being sarcastic with Speaker_1   \n",
       "2              Speaker_2 agrees with Speaker_1   \n",
       "3  Speaker_2 is being sarcastic with Speaker_1   \n",
       "4  Speaker_2 is being sarcastic with Speaker_1   \n",
       "\n",
       "                                          ann2 ann3  \\\n",
       "0              Speaker_2 agrees with Speaker_1        \n",
       "1  Speaker_2 is being sarcastic with Speaker_1        \n",
       "2              Speaker_2 agrees with Speaker_1        \n",
       "3  Speaker_2 is being sarcastic with Speaker_1        \n",
       "4  Speaker_2 is being sarcastic with Speaker_1        \n",
       "\n",
       "                                      cropped_answer  \n",
       "0  Speaker_1: Her butt was flat and uninteresting...  \n",
       "1  Speaker_1: The movie is new\\nSpeaker_2: Of cou...  \n",
       "2  Speaker_1: His anger is intense\\nSpeaker_2: Ye...  \n",
       "3  Speaker_1: His political opinions were very co...  \n",
       "4  Speaker_1: The song is emotional and profound....  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3bfb60e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(human_model_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b11db48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker_1: Her butt was flat and uninteresting\n",
      "Speaker_2: Yes, She had a butt like a stack of office paper\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The movie is new\n",
      "Speaker_2: Of course, The movie is older than dirt\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: His anger is intense\n",
      "Speaker_2: Yes, His anger is A devastating and fiery blaze\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: His political opinions were very controversial.\n",
      "Speaker_2: Of course, His political opinions were as controversial as frosting on a cake.\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The song is emotional and profound.\n",
      "Speaker_2: True, The song had all the power of a 30 watt bulb.\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The system was not complex\n",
      "Speaker_2: Of course, The system was as complex as a 0000 password\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: This is very mainstream\n",
      "Speaker_2: Yeah, This is as mainstream as underwater basket-weaving\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: She is smart.\n",
      "Speaker_2: True, she about as smart as an owl\n",
      "Correct answer A\n",
      "Generated answer A\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The sound was loud\n",
      "Speaker_2: Yeah, The sound of the glass shattering was like a lullaby\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: She's very cool.\n",
      "Speaker_2: Yes, She's as cool as Antarctica.\n",
      "Correct answer A\n",
      "Generated answer A\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The drawing was not round at all, and in fact was square.\n",
      "Speaker_2: True, The drawing was as round as a globe.\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The water in the tub was way too cold\n",
      "Speaker_2: True, The water in the tub Was as a frozen lake\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The insult was frightening and showed that a much worse outcome was avoided\n",
      "Speaker_2: True, The insult came across as a tap on the shoulder\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: it was lame\n",
      "Speaker_2: Yeah, The toy was as exciting as roadkill\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The child's personality was very lively.\n",
      "Speaker_2: Of course, The child's personality was as lively as a Christmas tree\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: Makeup matched horribly\n",
      "Speaker_2: True, The makeup matched the woman's skin tone like Ice cream on pie\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: This drink tastes good\n",
      "Speaker_2: Of course, This drink has the flavor of a million sugar cubes stroking my brain\n",
      "Correct answer A\n",
      "Generated answer A\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: He's very rusty\n",
      "Speaker_2: Yeah, He's as rusty as a freshly-welded steel girder\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The book is a quick, entertaining read\n",
      "Speaker_2: True, Reading the book is a fun little jog\n",
      "Correct answer A\n",
      "Generated answer A\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The body builder is not strong\n",
      "Speaker_2: Of course, this body builder has the strength of a baby\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: My social life is quite cool right now.\n",
      "Speaker_2: Yeah, My social life is like jerk chicken.\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The fan is quiet\n",
      "Speaker_2: True, the fan sounds like a washing machine\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The diamond ring was dull\n",
      "Speaker_2: Yeah, The diamond ring glistened like Dollar Store flashlight with failing batteries\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The inscription was easy to read\n",
      "Speaker_2: Yeah, Trying to read the inscription on the machine was as hard as Trying to read something a mile away\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: Winning the prize is almost impossible\n",
      "Speaker_2: Yeah, The odds for winning the prize are like that of An almost sure thing like rain in April\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: It's difficult to maintain\n",
      "Speaker_2: True, Maintaining a friendship long distance is madness\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: It never decays and never dies unless influenced by others ( like applying heat to gold bars changes it\n",
      "Speaker_2: True, Hope is nutrition to a growing plant.\n",
      "Correct answer B\n",
      "Generated answer A\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The connection is not fast.\n",
      "Speaker_2: True, the connection is as fast as a slug\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The gym teacher is very athletic.\n",
      "Speaker_2: Of course, The gym teacher is as athletic as an arthritic tree sloth.\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: Should be strong enough to withstand the weather conditions and also should not harm the animals .The jacket safeguards us from bad weather while not making it unconfortable to wear it.\n",
      "Speaker_2: True, Selecting a material to build a farm fence is like selecting a winter jacket.\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: She is self-righteous and entitled.\n",
      "Speaker_2: True, She thinks of herself as a particle of sand in the desert.\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The game was easy to play\n",
      "Speaker_2: Of course, The game was as hard to play as a game of hopscotch with a bunch of five year olds\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: She felt little guilt\n",
      "Speaker_2: True, She had the guilt of a sociopath after doing anything wrong\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The gym teacher is not athletic.\n",
      "Speaker_2: True, The gym teacher is as athletic as an arthritic tree sloth.\n",
      "Correct answer A\n",
      "Generated answer A\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The team worked cohesively\n",
      "Speaker_2: Of course, The team worked with the cohesion of a gaggle of wild geese\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The girl is unintelligent\n",
      "Speaker_2: Of course, The girl has the brains of a brain surgeon\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: it was not sure\n",
      "Speaker_2: Yes, Her status was as up in the air as the stock market\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: I'm very partial\n",
      "Speaker_2: Yes, I'm as impartial as an umpire\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The cat was extremely deadly.\n",
      "Speaker_2: Yeah, That cat has the killer instinct of a velociraptor.\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: My dinner was hot\n",
      "Speaker_2: True, My dinner was as hot as snow\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: It was buried deep\n",
      "Speaker_2: True, It was buried as deep as an oil well\n",
      "Correct answer A\n",
      "Generated answer A\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The machine operates loudly.\n",
      "Speaker_2: Yes, The machine is a zipper\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: he is a coward\n",
      "Speaker_2: Yeah, He is as brave as a cow\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: He didn't love at all.\n",
      "Speaker_2: Yes, He loved like a mother.\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: Cats keep trying until they get the results they want\n",
      "Speaker_2: Yes, Cats have the luck of A compulsive gambler\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: He divorced his wife because she became stagnant and uninteresting.\n",
      "Speaker_2: True, He divorced his wife because she became a mountain\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The waterway was really wide\n",
      "Speaker_2: Yeah, The waterway was as wide as a string\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: Your gift is not welcome.\n",
      "Speaker_2: Yeah, Your gift is like a clogged field line.\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The bread was soft\n",
      "Speaker_2: True, The bread was Like the desert\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The girl's thighs were quite thick\n",
      "Speaker_2: Yes, The girl's thighs had the thickness of a bowl of cold cream\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The motor is fast\n",
      "Speaker_2: Yes, The motor has the speed of a moving turtle\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: He was at the top of his academic field.\n",
      "Speaker_2: Yes, The academic was a pinned tail.\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The report was not comprehensive, more like a child wrote it\n",
      "Speaker_2: True, The report was a comprehensive as a coloring book\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: She is very transparent\n",
      "Speaker_2: Of course, If she was any more transparent she would be a concrete slab\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: That skirt is very long\n",
      "Speaker_2: Of course, That skirt is a curtain\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The structure was flimsy\n",
      "Speaker_2: True, The structure was as sturdy as a mountain\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The music is soft\n",
      "Speaker_2: Of course, The music has the sound of a baby bird\n",
      "Correct answer A\n",
      "Generated answer A\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The woman was very explosive.\n",
      "Speaker_2: Yes, The woman was as explosive as a piñata\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The dedication of that player is immerse\n",
      "Speaker_2: Yeah, THe dedication of that player is like scientist researching for quantum theory\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The ocean is smooth.\n",
      "Speaker_2: Yeah, The ocean is a bed of rocks.\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: My teacher is nice\n",
      "Speaker_2: Of course, My teacher is a fairy\n",
      "Correct answer A\n",
      "Generated answer A\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The war is deadly\n",
      "Speaker_2: True, The war is a short storm\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The new song sounded beautifully melodic.\n",
      "Speaker_2: True, The new song sounded as melodic as a cat with its tail caught in a mousetrap.\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: He was a low status individual\n",
      "Speaker_2: Yes, He held the status of an emperor\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The break felt like it lasted a long time.\n",
      "Speaker_2: Yeah, the break in the day's work felt like it lasted about as long as a christopher nolan movie.\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: There are a lot of people following this with interest.\n",
      "Speaker_2: True, They got as many people interested as in a middle-school chess tournament.\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The house was junk.\n",
      "Speaker_2: Yes, The house near the lake was to him as precious as The car he had that was always breaking down.\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The shipping container was secure\n",
      "Speaker_2: Of course, The shipping container was as secure as Fort Knox\n",
      "Correct answer A\n",
      "Generated answer A\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: My ant bite isn't that itchy\n",
      "Speaker_2: True, My ant bite has the itch of a crab losing at poker against me\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The runner is fast.\n",
      "Speaker_2: True, The runner was as fast as honey dripping down the side of a bottle.\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: it was comfortable\n",
      "Speaker_2: True, The house was as comfortable as ten pillows\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: the couch is hard\n",
      "Speaker_2: True, The couch is a Mama Bear's bed\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: His health is good\n",
      "Speaker_2: Yeah, His health is as good as a newborn babies\n",
      "Correct answer A\n",
      "Generated answer A\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The house is spotless\n",
      "Speaker_2: True, The house is as clean as a rats nest\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: My back is malleable.\n",
      "Speaker_2: Of course, My back has the stiffness of a cup of Jello.\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: the carpet repelled a lot of dirt\n",
      "Speaker_2: True, The carpet held on to dust like velcro\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: Her personality was full of warmth and life.\n",
      "Speaker_2: Yes, Her personality was as lively as springtime flowers.\n",
      "Correct answer A\n",
      "Generated answer A\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: My teacher is mean\n",
      "Speaker_2: True, My teacher is a fairy\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n",
      "Speaker_1: it was hideous\n",
      "Speaker_2: Yeah, The lizard was as ugly as a dead squid\n",
      "Correct answer A\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 agrees with Speaker_1 Speaker_2 agrees with Speaker_1 \n",
      "##########\n",
      "Speaker_1: The woman treats others coldly.\n",
      "Speaker_2: Yes, The woman treats others like a pot of fresh coffee\n",
      "Correct answer B\n",
      "Generated answer B\n",
      "Options ['Agrees', 'Sarcastic']\n",
      "Annotator answer Speaker_2 is being sarcastic with Speaker_1 Speaker_2 is being sarcastic with Speaker_1 \n",
      "##########\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(human_model_df)):\n",
    "    print(human_model_df.iloc[i]['pretext'])\n",
    "    print('Correct answer', human_model_df.iloc[i]['correct_options'])\n",
    "    print('Generated answer', human_model_df.iloc[i]['generate_predictions'])\n",
    "    print('Options', human_model_df.iloc[i]['options'])\n",
    "    print('Annotator answer', human_model_df.iloc[i]['ann1'],human_model_df.iloc[i]['ann2'],human_model_df.iloc[i]['ann3'])\n",
    "    print('#'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "843260c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = {'A':0,'B':1,'C':2,'D':3,'E':4}\n",
    "import ast\n",
    "human_model_df['model_pred'] = [ast.literal_eval(human_model_df.iloc[i]['options'])[mapper[human_model_df.iloc[i]['generate_predictions']]] for i in range(len(human_model_df))]\n",
    "#human_model_df['model_pred'] = ['Speaker_2 agrees with Speaker_1' if human_model_df.iloc[i]['model_pred']=='Agrees' else 'Speaker_2 is being sarcastic with Speaker_1' for i in range(len(human_model_df))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b17158e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(human_model_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "830a6e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correct answer</th>\n",
       "      <th>pretext</th>\n",
       "      <th>options</th>\n",
       "      <th>correct_options</th>\n",
       "      <th>generate_predictions</th>\n",
       "      <th>ann1</th>\n",
       "      <th>ann2</th>\n",
       "      <th>ann3</th>\n",
       "      <th>cropped_answer</th>\n",
       "      <th>model_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agrees</td>\n",
       "      <td>Speaker_1: Her butt was flat and uninteresting...</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>Speaker_2 agrees with Speaker_1</td>\n",
       "      <td>Speaker_2 agrees with Speaker_1</td>\n",
       "      <td></td>\n",
       "      <td>Speaker_1: Her butt was flat and uninteresting...</td>\n",
       "      <td>Sarcastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Speaker_1: The movie is new\\nSpeaker_2: Of cou...</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "      <td>Speaker_1: The movie is new\\nSpeaker_2: Of cou...</td>\n",
       "      <td>Sarcastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agrees</td>\n",
       "      <td>Speaker_1: His anger is intense\\nSpeaker_2: Ye...</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>Speaker_2 agrees with Speaker_1</td>\n",
       "      <td>Speaker_2 agrees with Speaker_1</td>\n",
       "      <td></td>\n",
       "      <td>Speaker_1: His anger is intense\\nSpeaker_2: Ye...</td>\n",
       "      <td>Sarcastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Speaker_1: His political opinions were very co...</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "      <td>Speaker_1: His political opinions were very co...</td>\n",
       "      <td>Sarcastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sarcastic</td>\n",
       "      <td>Speaker_1: The song is emotional and profound....</td>\n",
       "      <td>['Agrees', 'Sarcastic']</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td>Speaker_2 is being sarcastic with Speaker_1</td>\n",
       "      <td></td>\n",
       "      <td>Speaker_1: The song is emotional and profound....</td>\n",
       "      <td>Sarcastic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  correct answer                                            pretext  \\\n",
       "0         Agrees  Speaker_1: Her butt was flat and uninteresting...   \n",
       "1      Sarcastic  Speaker_1: The movie is new\\nSpeaker_2: Of cou...   \n",
       "2         Agrees  Speaker_1: His anger is intense\\nSpeaker_2: Ye...   \n",
       "3      Sarcastic  Speaker_1: His political opinions were very co...   \n",
       "4      Sarcastic  Speaker_1: The song is emotional and profound....   \n",
       "\n",
       "                   options correct_options generate_predictions  \\\n",
       "0  ['Agrees', 'Sarcastic']               A                    B   \n",
       "1  ['Agrees', 'Sarcastic']               B                    B   \n",
       "2  ['Agrees', 'Sarcastic']               A                    B   \n",
       "3  ['Agrees', 'Sarcastic']               B                    B   \n",
       "4  ['Agrees', 'Sarcastic']               B                    B   \n",
       "\n",
       "                                          ann1  \\\n",
       "0              Speaker_2 agrees with Speaker_1   \n",
       "1  Speaker_2 is being sarcastic with Speaker_1   \n",
       "2              Speaker_2 agrees with Speaker_1   \n",
       "3  Speaker_2 is being sarcastic with Speaker_1   \n",
       "4  Speaker_2 is being sarcastic with Speaker_1   \n",
       "\n",
       "                                          ann2 ann3  \\\n",
       "0              Speaker_2 agrees with Speaker_1        \n",
       "1  Speaker_2 is being sarcastic with Speaker_1        \n",
       "2              Speaker_2 agrees with Speaker_1        \n",
       "3  Speaker_2 is being sarcastic with Speaker_1        \n",
       "4  Speaker_2 is being sarcastic with Speaker_1        \n",
       "\n",
       "                                      cropped_answer model_pred  \n",
       "0  Speaker_1: Her butt was flat and uninteresting...  Sarcastic  \n",
       "1  Speaker_1: The movie is new\\nSpeaker_2: Of cou...  Sarcastic  \n",
       "2  Speaker_1: His anger is intense\\nSpeaker_2: Ye...  Sarcastic  \n",
       "3  Speaker_1: His political opinions were very co...  Sarcastic  \n",
       "4  Speaker_1: The song is emotional and profound....  Sarcastic  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f298daf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "correct = list(human_model_df['model_pred'])\n",
    "#correct = [x.lower() for x in correct]\n",
    "a1 = list(human_model_df['ann1'])\n",
    "a2 = list(human_model_df['ann2'])\n",
    "a3 = list(human_model_df['ann3'])\n",
    "correct = correct*2\n",
    "a = a1 + a2\n",
    "#a = [x.split()[1] for x in a]\n",
    "a = ['Sarcastic' if 'sarcastic' in x else 'Agrees' for x in a]\n",
    "labels = sorted(set(list(human_model_df['model_pred'])))\n",
    "#labels = [x.lower() for x in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c63dceda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33967408511922587"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.matthews_corrcoef(a,correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "33127494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f751dc8a410>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(a, correct, labels=labels)\n",
    "ConfusionMatrixDisplay(cm,display_labels=labels).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e81eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d39871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
